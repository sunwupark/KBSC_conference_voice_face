# -*- coding: utf-8 -*-
"""Face_Emotion_Recognition.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1H2t2De9SpwfXDH3ZrwDTBXClglTdXApu
"""

# Commented out IPython magic to ensure Python compatibility.

import numpy as np
import cv2
from keras.models import load_model
import dlib

class face_exp():
    def __init__(self):
        self.model = load_model("./models/expression/face_exp_model.h5")
       
    def predict(self,filepath):
        emotions = ('anger', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')
        img=cv2.imread(filepath)
        img=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        #img = cv2.resize(img, (48,48))
        face_detector=dlib.get_frontal_face_detector()
        faces=face_detector(img)
        if (len(faces) == 0):
            return "Not Recognized."
        for f in faces:
            crop=img[f.top():f.bottom(),f.left():f.right()]
        
        print('crop shape : {}'.format(crop.shape))
        crop = cv2.resize(crop, (48, 48))
        output = emotions[np.argmax(self.model.predict(crop.reshape((1,48,48,1))), axis=-1)[0]]
        print('face expression output : {}'.format(output))
        return output
